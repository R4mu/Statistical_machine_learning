{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1.Importing Libraries #\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import *\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2.Reading Dataset #\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "file_path = 'training_data_fall2024.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "# Preserving the label encoder used for 'increase_stock'\n",
    "increase_stock_encoder = label_encoder.fit(data[data.columns[15]])\n",
    "data[data.columns[15]]= increase_stock_encoder.transform(data[data.columns[15]])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3.Data Pre-Processing Step #\n",
    "# Check for missing values\n",
    "missing_values = data.isnull().sum()\n",
    "# Display columns with missing values\n",
    "missing_values[missing_values>0]\n",
    "# Print missing values\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4. Handling Categorical Data #\n",
    "# Encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "data['increase_stock'] = label_encoder.fit_transform(data['increase_stock'])\n",
    "# Check the mapping of the categories to numbers\n",
    "label_mapping = dict(zip(label_encoder.classes_,label_encoder.transform(label_encoder.classes_)))\n",
    "print(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5. Dependent and independent variables #\n",
    "# Define features (X) and target (y)\n",
    "X = data.drop(columns=['increase_stock'])\n",
    "y = data['increase_stock']\n",
    "# Display the shapes of X and y\n",
    "print(X.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6. Splitting dataset into training and testing set #\n",
    "# Split the dataset into training and testing sets\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.2,random_state=0)\n",
    "# Display the shapes of the training and testing set\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7. Implementing a Random Forest Classifier #\n",
    "# Initialize and train a random forest classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=0)\n",
    "rf_classifier.fit(X_train,y_train)\n",
    "# Check features importances for interpretability\n",
    "feature_importances = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'importance': rf_classifier.feature_importances_\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "# Display feature importance\n",
    "print(feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8. Predicting testcases using Random Forest #\n",
    "# Make prediction on the test set\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "# Display predictions for a sample of test set\n",
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9. Checking accuracy score #\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test,y_pred)\n",
    "# Instead of using the encoder, define target names directly as strings\n",
    "target_names = ['Decrease', 'Increase']\n",
    "# Generate a classification report with the string target names\n",
    "class_report = classification_report(y_test, y_pred, target_names=target_names)\n",
    "print(accuracy,class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10.Random search to tune the Random Forest Method #\n",
    "# Define parameter distribution\n",
    "data_array = np.array(data, dtype=float)\n",
    "X = data_array[:, :-1]\n",
    "y = data_array[:, -1]\n",
    "pram_dist = {\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "# Initialize RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator = RandomForestClassifier(random_state=0),\n",
    "    param_distributions=pram_dist,\n",
    "    n_iter=20,\n",
    "    cv=3,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    random_state=0\n",
    ")\n",
    "# Fitting the model\n",
    "random_search.fit(X_train,y_train)\n",
    "# Output of parameters and score\n",
    "print(\"Best Parameters:\",random_search.best_params_)\n",
    "print(\"Best Cross Vadidation Score:\",random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 11. Inserting or creating new Feature to test the Random Forests performance #\n",
    "# Convert X back to DataFrame to use column names:\n",
    "X = pd.DataFrame(X, columns=data.columns[:-1])  # Assuming original columns are in 'data'\n",
    "\n",
    "# Now you can use column names for calculations:\n",
    "X['temp_dew_diff'] = X['temp'] - X['dew']\n",
    "\n",
    "# Updating the training and testing data with new features\n",
    "# Convert X back to a NumPy array for train_test_split if necessary:\n",
    "X = X.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Initialize the Random Forest with predefined parameters\n",
    "predefined_rf = RandomForestClassifier(\n",
    "n_estimators=100,\n",
    "max_depth=20,\n",
    "min_samples_split=5,\n",
    "min_samples_leaf=2,\n",
    "random_state=0\n",
    ")\n",
    "# Perform 5-Fold cross validation\n",
    "cv_score = cross_val_score(predefined_rf,X_train,y_train,cv=5,scoring='accuracy')\n",
    "# Calculate mean and standard deviation of cross validation scores\n",
    "cv_mean = np.mean(cv_score)\n",
    "cv_std = np.std(cv_score)\n",
    "print(cv_mean,cv_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 12. Assuming y_test contains the true labels and y_pred contains the predicted labels #\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Classification Model\n",
    "# Extract the target variable\n",
    "y_true = data['increase_stock']\n",
    "\n",
    "# Method 1: Always predict 'low_bike_demand'\n",
    "y_pred_low = ['low_bike_demand'] * len(y_true)\n",
    "\n",
    "# Method 2: Always predict 'high_bike_demand'\n",
    "y_pred_high = ['high_bike_demand'] * len(y_true)\n",
    "\n",
    "# Method 3: Random predictions\n",
    "np.random.seed(0)  # For reproducibility\n",
    "y_pred_random = np.random.choice(['low_bike_demand', 'high_bike_demand'], size=len(y_true))\n",
    "\n",
    "# Compare predictions\n",
    "print(\"Sample predictions:\")\n",
    "print(f\"Always 'low_bike_demand': {y_pred_low[:3]}\")\n",
    "print(f\"Always 'high_bike_demand': {y_pred_high[:3]}\")\n",
    "print(f\"Random predictions: {y_pred_random[:3]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
